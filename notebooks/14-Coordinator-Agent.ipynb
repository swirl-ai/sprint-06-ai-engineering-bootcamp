{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57fdc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmcp import Client\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Prefetch, Filter, FieldCondition, MatchText, FusionQuery, MatchValue\n",
    "\n",
    "from langsmith import traceable, get_current_run_tree\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "from jinja2 import Template\n",
    "from typing import Literal, Dict, Any, Annotated, List, Optional\n",
    "from IPython.display import Image, display\n",
    "from operator import add\n",
    "from openai import OpenAI\n",
    "\n",
    "import openai\n",
    "\n",
    "import random\n",
    "import ast\n",
    "import inspect\n",
    "import instructor\n",
    "import json\n",
    "\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "from psycopg2.extras import RealDictCursor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee90198",
   "metadata": {},
   "source": [
    "### Helper Functions needed to run the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c38759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_docstring_params(docstring: str) -> Dict[str, str]:\n",
    "    \"\"\"Extract parameter descriptions from docstring (handles both Args: and Parameters: formats).\"\"\"\n",
    "    params = {}\n",
    "    lines = docstring.split('\\n')\n",
    "    in_params = False\n",
    "    current_param = None\n",
    "    \n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        \n",
    "        # Check for parameter section start\n",
    "        if stripped in ['Args:', 'Arguments:', 'Parameters:', 'Params:']:\n",
    "            in_params = True\n",
    "            current_param = None\n",
    "        elif stripped.startswith('Returns:') or stripped.startswith('Raises:'):\n",
    "            in_params = False\n",
    "        elif in_params:\n",
    "            # Parse parameter line (handles \"param: desc\" and \"- param: desc\" formats)\n",
    "            if ':' in stripped and (stripped[0].isalpha() or stripped.startswith(('-', '*'))):\n",
    "                param_name = stripped.lstrip('- *').split(':')[0].strip()\n",
    "                param_desc = ':'.join(stripped.lstrip('- *').split(':')[1:]).strip()\n",
    "                params[param_name] = param_desc\n",
    "                current_param = param_name\n",
    "            elif current_param and stripped:\n",
    "                # Continuation of previous parameter description\n",
    "                params[current_param] += ' ' + stripped\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78593a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_tool_descriptions_from_mcp_servers(mcp_servers: list[str]) -> list[dict]:\n",
    "\n",
    "    tool_descriptions = []\n",
    "\n",
    "    for server in mcp_servers:\n",
    "\n",
    "        client = Client(server)\n",
    "\n",
    "        async with client:\n",
    "\n",
    "            tools = await client.list_tools()\n",
    "\n",
    "            for tool in tools:\n",
    "                \n",
    "                result = {\n",
    "                    \"name\": \"\",\n",
    "                    \"description\": \"\",\n",
    "                    \"parameters\": {\"type\": \"object\", \"properties\": {}},\n",
    "                    \"required\": [],\n",
    "                    \"returns\": {\"type\": \"string\", \"description\": \"\"},\n",
    "                    \"server\": server\n",
    "                }\n",
    "\n",
    "                result[\"name\"] = tool.name\n",
    "                result[\"required\"] = tool.inputSchema.get(\"required\", [])\n",
    "\n",
    "                ## Get Description\n",
    "\n",
    "                description = tool.description.split(\"\\n\\n\")[0]\n",
    "                result[\"description\"] = description\n",
    "\n",
    "\n",
    "                ## Get Returns\n",
    "\n",
    "                returns = tool.description.split(\"Returns:\")[1].strip()\n",
    "                result[\"returns\"][\"description\"] = returns\n",
    "\n",
    "                ## Get parameters\n",
    "\n",
    "                property_descriptions = parse_docstring_params(tool.description)\n",
    "                properties = tool.inputSchema.get(\"properties\", {})\n",
    "                for key, value in properties.items():\n",
    "                    properties[key][\"description\"] = property_descriptions.get(key, \"\")\n",
    "\n",
    "                result[\"parameters\"][\"properties\"] = properties\n",
    "\n",
    "                tool_descriptions.append(result)\n",
    "\n",
    "    return tool_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad134143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lc_messages_to_regular_messages(msg):\n",
    "\n",
    "    if isinstance(msg, dict):\n",
    "        \n",
    "        if msg.get(\"role\") == \"user\":\n",
    "            return {\"role\": \"user\", \"content\": msg[\"content\"]}\n",
    "        elif msg.get(\"role\") == \"assistant\":\n",
    "            return {\"role\": \"assistant\", \"content\": msg[\"content\"]}\n",
    "        elif msg.get(\"role\") == \"tool\":\n",
    "            return {\n",
    "                \"role\": \"tool\", \n",
    "                \"content\": msg[\"content\"], \n",
    "                \"tool_call_id\": msg.get(\"tool_call_id\")\n",
    "            }\n",
    "        \n",
    "    elif isinstance(msg, AIMessage):\n",
    "\n",
    "        result = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": msg.content\n",
    "        }\n",
    "        \n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls and len(msg.tool_calls) > 0 and not msg.tool_calls[0].get(\"name\").startswith(\"functions.\"):\n",
    "            result[\"tool_calls\"] = [\n",
    "                {\n",
    "                    \"id\": tc[\"id\"],\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tc[\"name\"].replace(\"functions.\", \"\"),\n",
    "                        \"arguments\": json.dumps(tc[\"args\"])\n",
    "                    }\n",
    "                }\n",
    "                for tc in msg.tool_calls\n",
    "            ]\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    elif isinstance(msg, ToolMessage):\n",
    "\n",
    "        return {\"role\": \"tool\", \"content\": msg.content, \"tool_call_id\": msg.tool_call_id}\n",
    "    \n",
    "    else:\n",
    "\n",
    "        return {\"role\": \"user\", \"content\": str(msg)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0854bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function_definition(function_def: str) -> Dict[str, Any]:\n",
    "    \"\"\"Parse a function definition string to extract metadata including type hints.\"\"\"\n",
    "    result = {\n",
    "        \"name\": \"\",\n",
    "        \"description\": \"\",\n",
    "        \"parameters\": {\"type\": \"object\", \"properties\": {}},\n",
    "        \"required\": [],\n",
    "        \"returns\": {\"type\": \"string\", \"description\": \"\"}\n",
    "    }\n",
    "    \n",
    "    # Parse the function using AST\n",
    "    tree = ast.parse(function_def.strip())\n",
    "    if not tree.body or not isinstance(tree.body[0], ast.FunctionDef):\n",
    "        return result\n",
    "        \n",
    "    func = tree.body[0]\n",
    "    result[\"name\"] = func.name\n",
    "    \n",
    "    # Extract docstring\n",
    "    docstring = ast.get_docstring(func) or \"\"\n",
    "    if docstring:\n",
    "        # Extract description (first line/paragraph)\n",
    "        desc_end = docstring.find('\\n\\n') if '\\n\\n' in docstring else docstring.find('\\nArgs:')\n",
    "        desc_end = desc_end if desc_end > 0 else docstring.find('\\nParameters:')\n",
    "        result[\"description\"] = docstring[:desc_end].strip() if desc_end > 0 else docstring.strip()\n",
    "        \n",
    "        # Parse parameter descriptions\n",
    "        param_descs = parse_docstring_params(docstring)\n",
    "        \n",
    "        # Extract return description\n",
    "        if \"Returns:\" in docstring:\n",
    "            result[\"returns\"][\"description\"] = docstring.split(\"Returns:\")[1].strip().split('\\n')[0]\n",
    "    \n",
    "    # Extract parameters with type hints\n",
    "    args = func.args\n",
    "    defaults = args.defaults\n",
    "    num_args = len(args.args)\n",
    "    num_defaults = len(defaults)\n",
    "    \n",
    "    for i, arg in enumerate(args.args):\n",
    "        if arg.arg == 'self':\n",
    "            continue\n",
    "            \n",
    "        param_info = {\n",
    "            \"type\": get_type_from_annotation(arg.annotation) if arg.annotation else \"string\",\n",
    "            \"description\": param_descs.get(arg.arg, \"\")\n",
    "        }\n",
    "        \n",
    "        # Check for default value\n",
    "        default_idx = i - (num_args - num_defaults)\n",
    "        if default_idx >= 0:\n",
    "            param_info[\"default\"] = ast.literal_eval(ast.unparse(defaults[default_idx]))\n",
    "        else:\n",
    "            result[\"required\"].append(arg.arg)\n",
    "        \n",
    "        result[\"parameters\"][\"properties\"][arg.arg] = param_info\n",
    "    \n",
    "    # Extract return type\n",
    "    if func.returns:\n",
    "        result[\"returns\"][\"type\"] = get_type_from_annotation(func.returns)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def get_type_from_annotation(annotation) -> str:\n",
    "    \"\"\"Convert AST annotation to type string.\"\"\"\n",
    "    if not annotation:\n",
    "        return \"string\"\n",
    "    \n",
    "    type_map = {\n",
    "        'str': 'string',\n",
    "        'int': 'integer', \n",
    "        'float': 'number',\n",
    "        'bool': 'boolean',\n",
    "        'list': 'array',\n",
    "        'dict': 'object',\n",
    "        'List': 'array',\n",
    "        'Dict': 'object'\n",
    "    }\n",
    "    \n",
    "    if isinstance(annotation, ast.Name):\n",
    "        return type_map.get(annotation.id, annotation.id)\n",
    "    elif isinstance(annotation, ast.Subscript) and isinstance(annotation.value, ast.Name):\n",
    "        base_type = annotation.value.id\n",
    "        return type_map.get(base_type, base_type.lower())\n",
    "    \n",
    "    return \"string\"\n",
    "\n",
    "\n",
    "def parse_docstring_params(docstring: str) -> Dict[str, str]:\n",
    "    \"\"\"Extract parameter descriptions from docstring (handles both Args: and Parameters: formats).\"\"\"\n",
    "    params = {}\n",
    "    lines = docstring.split('\\n')\n",
    "    in_params = False\n",
    "    current_param = None\n",
    "    \n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        \n",
    "        # Check for parameter section start\n",
    "        if stripped in ['Args:', 'Arguments:', 'Parameters:', 'Params:']:\n",
    "            in_params = True\n",
    "            current_param = None\n",
    "        elif stripped.startswith('Returns:') or stripped.startswith('Raises:'):\n",
    "            in_params = False\n",
    "        elif in_params:\n",
    "            # Parse parameter line (handles \"param: desc\" and \"- param: desc\" formats)\n",
    "            if ':' in stripped and (stripped[0].isalpha() or stripped.startswith(('-', '*'))):\n",
    "                param_name = stripped.lstrip('- *').split(':')[0].strip()\n",
    "                param_desc = ':'.join(stripped.lstrip('- *').split(':')[1:]).strip()\n",
    "                params[param_name] = param_desc\n",
    "                current_param = param_name\n",
    "            elif current_param and stripped:\n",
    "                # Continuation of previous parameter description\n",
    "                params[current_param] += ' ' + stripped\n",
    "    \n",
    "    return params\n",
    "\n",
    "\n",
    "def get_tool_descriptions_from_node(tool_node):\n",
    "    \"\"\"Extract tool descriptions from the ToolNode object.\"\"\"\n",
    "    descriptions = []\n",
    "    \n",
    "    if hasattr(tool_node, 'tools_by_name'):\n",
    "        tools_by_name = tool_node.tools_by_name\n",
    "        \n",
    "        for tool_name, tool in tools_by_name.items():\n",
    "            function_string = inspect.getsource(globals()[tool_name])\n",
    "            # function_string = inspect.getsource(getattr(tool_name))\n",
    "            result = parse_function_definition(function_string)\n",
    "\n",
    "            if result:\n",
    "                descriptions.append(result)\n",
    "    \n",
    "    return descriptions if descriptions else \"Could not extract tool descriptions\"\n",
    "\n",
    "\n",
    "def lc_messages_to_regular_messages(msg):\n",
    "\n",
    "    if isinstance(msg, dict):\n",
    "        \n",
    "        if msg.get(\"role\") == \"user\":\n",
    "            return {\"role\": \"user\", \"content\": msg[\"content\"]}\n",
    "        elif msg.get(\"role\") == \"assistant\":\n",
    "            return {\"role\": \"assistant\", \"content\": msg[\"content\"]}\n",
    "        elif msg.get(\"role\") == \"tool\":\n",
    "            return {\n",
    "                \"role\": \"tool\", \n",
    "                \"content\": msg[\"content\"], \n",
    "                \"tool_call_id\": msg.get(\"tool_call_id\")\n",
    "            }\n",
    "        \n",
    "    elif isinstance(msg, AIMessage):\n",
    "\n",
    "        result = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": msg.content\n",
    "        }\n",
    "        \n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls and len(msg.tool_calls) > 0 and not msg.tool_calls[0].get(\"name\").startswith(\"functions.\"):\n",
    "            result[\"tool_calls\"] = [\n",
    "                {\n",
    "                    \"id\": tc[\"id\"],\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tc[\"name\"].replace(\"functions.\", \"\"),\n",
    "                        \"arguments\": json.dumps(tc[\"args\"])\n",
    "                    }\n",
    "                }\n",
    "                for tc in msg.tool_calls\n",
    "            ]\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    elif isinstance(msg, ToolMessage):\n",
    "\n",
    "        return {\"role\": \"tool\", \"content\": msg.content, \"tool_call_id\": msg.tool_call_id}\n",
    "    \n",
    "    else:\n",
    "\n",
    "        return {\"role\": \"user\", \"content\": str(msg)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04476d11",
   "metadata": {},
   "source": [
    "### Pydantic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "    server: str\n",
    "\n",
    "class RAGUsedContext(BaseModel):\n",
    "    id: int\n",
    "    description: str\n",
    "\n",
    "class ProductQAAgentResponse(BaseModel):\n",
    "    answer: str\n",
    "    tool_calls: List[MCPToolCall] = Field(default_factory=list)\n",
    "    final_answer: bool = Field(default=False)\n",
    "    retrieved_context_ids: List[RAGUsedContext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9bbb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Delegation(BaseModel):\n",
    "    agent: str\n",
    "    task: str = Field(default=\"\")\n",
    "\n",
    "class CoordinatorAgentResponse(BaseModel):\n",
    "    next_agent: str\n",
    "    plan: list[Delegation]\n",
    "    final_answer: bool = Field(default=False)\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964890f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "\n",
    "class ShoppingCartAgentResponse(BaseModel):\n",
    "    answer: str\n",
    "    tool_calls: List[ToolCall] = Field(default_factory=list)\n",
    "    final_answer: bool = Field(default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301a2b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(BaseModel):\n",
    "    messages: Annotated[List[Any], add] = []\n",
    "    answer: str = \"\"\n",
    "    product_qa_iteration: int = Field(default=0)\n",
    "    shopping_cart_iteration: int = Field(default=0)\n",
    "    coordinator_iteration: int = Field(default=0)\n",
    "    product_qa_final_answer: bool = Field(default=False)\n",
    "    shopping_cart_final_answer: bool = Field(default=False)\n",
    "    coordinator_final_answer: bool = Field(default=False)\n",
    "    product_qa_available_tools: List[Dict[str, Any]] = []\n",
    "    shopping_cart_available_tools: List[Dict[str, Any]] = []\n",
    "    mcp_tool_calls: Optional[List[MCPToolCall]] = Field(default_factory=list)\n",
    "    tool_calls: Optional[List[ToolCall]] = Field(default_factory=list)\n",
    "    retrieved_context_ids: List[RAGUsedContext] = Field(default_factory=list)\n",
    "    user_id: str = \"\"\n",
    "    cart_id: str = \"\"\n",
    "    plan: list[Delegation] = Field(default_factory=list)\n",
    "    next_agent: str = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a386b",
   "metadata": {},
   "source": [
    "### The Product QA Agent Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a994738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"product_qa_agent\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1\"}\n",
    ")\n",
    "def product_qa_agent_node(state: State) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are an Agent, part of a shopping assistant that can answer questions about the products in stock.\n",
    "\n",
    "You will be given a conversation history and a list of tools you can use to answer that question.\n",
    "\n",
    "<Available tools>\n",
    "{{ available_tools | tojson }}\n",
    "</Available tools>\n",
    "\n",
    "After the tools are used you will get the outputs from the tools.\n",
    "\n",
    "When you need to use a tool, format your response as:\n",
    "\n",
    "<tool_call>\n",
    "{\"name\": \"tool_name\", \"arguments\": {...}}\n",
    "</tool_call>\n",
    "\n",
    "Use names specificly provided in the available tools. Don't add any additional text to the names.\n",
    "\n",
    "You should tend to use tools when additional information is needed to answer the question.\n",
    "\n",
    "CRITICAL RULES:\n",
    "- If tool_calls has values, final_answer MUST be false\n",
    "  (You cannot call tools and return to coordinator in the same response)\n",
    "- If final_answer is true, tool_calls MUST be []\n",
    "  (You must wait for tool results before returning to coordinator)\n",
    "- If you need tool results before answering, set:\n",
    "  tool_calls=[...], final_answer=false\n",
    "- After receiving tool results, you can then set:\n",
    "  tool_calls=[], final_answer=true\n",
    "\n",
    "Instructions:\n",
    "- You need to answer the question based on the retrieved context using the available tools only.\n",
    "- Never use word context and refer to it as the available products.\n",
    "- You should only answer questions about the products in stock. If the question is not about the products in stock, you should ask for clarification.\n",
    "- As a final output you need to provide:\n",
    "\n",
    "* The answer to the question based on the retrieved context.\n",
    "* The list of the indexes from the chunks returned from all tool calls that were used to answer the question. If more than one chunk was used to compile the answer from a single tool call, be sure to return all of them.\n",
    "* Short description of the item based on the retrieved context.\n",
    "\n",
    "- The answer to the question should contain detailed information about the product and returned with detailed specification in bullet points.\n",
    "- The short description should have the name of the item.\n",
    "- If the user's request requires using a tool, set tool_calls with the appropriate function name and arguments.\n",
    "- If you have all the information needed to provide a complete answer, set final_answer to True.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      available_tools=state.product_qa_available_tools\n",
    "   )\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for msg in messages:\n",
    "      conversation.append(lc_messages_to_regular_messages(msg))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=ProductQAAgentResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0,\n",
    "   )\n",
    "\n",
    "   if response.final_answer:\n",
    "      ai_message = AIMessage(\n",
    "         content=response.answer,\n",
    "      )\n",
    "   elif response.tool_calls:\n",
    "      tool_calls = []\n",
    "      for i, tc in enumerate(response.tool_calls):\n",
    "         tool_calls.append({\n",
    "               \"id\": f\"call_{i}\",\n",
    "               \"name\": tc.name,\n",
    "               \"args\": tc.arguments\n",
    "         })\n",
    "\n",
    "      ai_message = AIMessage(\n",
    "         content=response.answer,\n",
    "         tool_calls=tool_calls\n",
    "         )\n",
    "   else:\n",
    "      ai_message = AIMessage(\n",
    "         content=response.answer,\n",
    "      )\n",
    "\n",
    "   return {\n",
    "      \"messages\": [ai_message],\n",
    "      \"mcp_tool_calls\": response.tool_calls,\n",
    "      \"product_qa_iteration\": state.product_qa_iteration + 1,\n",
    "      \"answer\": response.answer,\n",
    "      \"product_qa_final_answer\": response.final_answer,\n",
    "      \"retrieved_context_ids\": response.retrieved_context_ids\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b73f2f5",
   "metadata": {},
   "source": [
    "### The Shopping Cart Agent Node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818465b9",
   "metadata": {},
   "source": [
    "#### Write to shopping cart tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91516007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_shopping_cart(items: list[dict], user_id: str, cart_id: str) -> str:\n",
    "\n",
    "    \"\"\"Add a list of provided items to the shopping cart.\n",
    "    \n",
    "    Args:\n",
    "        items: A list of items to add to the shopping cart. Each item is a dictionary with the following keys: product_id, quantity.\n",
    "        user_id: The id of the user to add the items to the shopping cart.\n",
    "        cart_id: The id of the shopping cart to add the items to.\n",
    "        \n",
    "    Returns:\n",
    "        A list of the items added to the shopping cart.\n",
    "    \"\"\"\n",
    "\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=5433,\n",
    "        database=\"langgraph_db\",\n",
    "        user=\"langgraph_user\",\n",
    "        password=\"langgraph_password\"\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "\n",
    "    with conn.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "        \n",
    "        for item in items:\n",
    "            product_id = item['product_id']\n",
    "            quantity = item['quantity']\n",
    "\n",
    "            qdrant_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "            dummy_vector = np.zeros(1536).tolist()\n",
    "            payload = qdrant_client.query_points(\n",
    "                collection_name=\"Amazon-items-collection-02-items\",\n",
    "                query=dummy_vector,\n",
    "                query_filter=Filter(\n",
    "                    must=[\n",
    "                        FieldCondition(\n",
    "                            key=\"parent_asin\",\n",
    "                            match=MatchValue(value=product_id)\n",
    "                        )\n",
    "                    ]\n",
    "                ),\n",
    "                with_payload=True,\n",
    "                limit=1\n",
    "            ).points[0].payload\n",
    "\n",
    "            product_image_url = payload.get(\"first_large_image\")\n",
    "            price = payload.get(\"price\")\n",
    "            currency = 'USD'\n",
    "        \n",
    "            # Check if item already exists\n",
    "            check_query = \"\"\"\n",
    "                SELECT id, quantity, price \n",
    "                FROM shopping_carts.shopping_cart_items \n",
    "                WHERE user_id = %s AND shopping_cart_id = %s AND product_id = %s\n",
    "            \"\"\"\n",
    "            cursor.execute(check_query, (user_id, cart_id, product_id))\n",
    "            existing_item = cursor.fetchone()\n",
    "            \n",
    "            if existing_item:\n",
    "                # Update existing item\n",
    "                new_quantity = existing_item['quantity'] + quantity\n",
    "                \n",
    "                update_query = \"\"\"\n",
    "                    UPDATE shopping_carts.shopping_cart_items \n",
    "                    SET \n",
    "                        quantity = %s,\n",
    "                        price = %s,\n",
    "                        currency = %s,\n",
    "                        product_image_url = COALESCE(%s, product_image_url)\n",
    "                    WHERE user_id = %s AND shopping_cart_id = %s AND product_id = %s\n",
    "                    RETURNING id, quantity, price\n",
    "                \"\"\"\n",
    "                \n",
    "                cursor.execute(update_query, (new_quantity, price, currency, product_image_url, user_id, cart_id, product_id))\n",
    "            \n",
    "            else:\n",
    "                # Insert new item\n",
    "                insert_query = \"\"\"\n",
    "                    INSERT INTO shopping_carts.shopping_cart_items (\n",
    "                        user_id, shopping_cart_id, product_id,\n",
    "                        price, quantity, currency, product_image_url\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "                    RETURNING id, quantity, price\n",
    "                \"\"\"\n",
    "                \n",
    "                cursor.execute(insert_query, (user_id, cart_id, product_id, price, quantity, currency, product_image_url))\n",
    "            \n",
    "    return f\"Added {items} to the shopping cart.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2348676e",
   "metadata": {},
   "source": [
    "#### Get the shopping cart tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b024a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shopping_cart(user_id: str, cart_id: str) -> list[dict]:\n",
    "\n",
    "    \"\"\"\n",
    "    Retrieve all items in a user's shopping cart.\n",
    "    \n",
    "    Args:\n",
    "        user_id: User ID\n",
    "        shopping_cart_id: Cart identifier\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing cart items\n",
    "    \"\"\"\n",
    "    \n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=5433,\n",
    "        database=\"langgraph_db\",\n",
    "        user=\"langgraph_user\",\n",
    "        password=\"langgraph_password\"\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "\n",
    "    with conn.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "\n",
    "        query = \"\"\"\n",
    "                SELECT \n",
    "                    product_id, price, quantity,\n",
    "                    currency, product_image_url,\n",
    "                    (price * quantity) as total_price\n",
    "                FROM shopping_carts.shopping_cart_items \n",
    "                WHERE user_id = %s AND shopping_cart_id = %s\n",
    "                ORDER BY added_at DESC\n",
    "            \"\"\"\n",
    "        cursor.execute(query, (user_id, cart_id))\n",
    "\n",
    "        return [dict(row) for row in cursor.fetchall()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37520a65",
   "metadata": {},
   "source": [
    "#### Delete from shopping cart tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d6cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_from_cart(product_id: str, user_id: str, cart_id: str) -> str:\n",
    "\n",
    "    \"\"\"\n",
    "    Remove an item completely from the shopping cart.\n",
    "    \n",
    "    Args:\n",
    "        user_id: User ID\n",
    "        product_id: Product ID to remove\n",
    "        shopping_cart_id: Cart identifier\n",
    "    \n",
    "    Returns:\n",
    "        True if item was removed, False if item wasn't found\n",
    "    \"\"\"\n",
    "    \n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=5433,\n",
    "        database=\"langgraph_db\",\n",
    "        user=\"langgraph_user\",\n",
    "        password=\"langgraph_password\"\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "\n",
    "    with conn.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "\n",
    "        query = \"\"\"\n",
    "                DELETE FROM shopping_carts.shopping_cart_items\n",
    "                WHERE user_id = %s AND shopping_cart_id = %s AND product_id = %s\n",
    "            \"\"\"\n",
    "        cursor.execute(query, (user_id, cart_id, product_id))\n",
    "\n",
    "        return cursor.rowcount > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575ccea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"shopping_cart_agent\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1\"}\n",
    ")\n",
    "def shopping_cart_agent_node(state) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are a part of the shopping assistant that can manage the user's shopping cart.\n",
    "\n",
    "You will be given a conversation history and a list of tools, your task is to perform the action requested by the latest user query.\n",
    "\n",
    "<Available tools>\n",
    "{{ available_tools | tojson }}\n",
    "</Available tools>\n",
    "\n",
    "When making tool calls, use this exact format:\n",
    "{\n",
    "   \"name\": \"tool_name\",\n",
    "   \"arguments\": {\n",
    "         \"parameter1\": \"value1\",\n",
    "         \"parameter2\": \"value2\",\n",
    "   }\n",
    "}\n",
    "\n",
    "CRITICAL: All parameters must go inside the \"arguments\" object, not at the top level of the tool call.\n",
    "\n",
    "Examples:\n",
    "- Remove item from shopping cart:\n",
    "{\n",
    "   \"name\": \"remove_from_shopping_cart\",\n",
    "   \"arguments\": {\n",
    "         \"product_id\": \"123\",\n",
    "         \"user_id\": \"123\",\n",
    "         \"cart_id\": \"456\"\n",
    "   }\n",
    "}\n",
    "\n",
    "- Add item to shopping cart:\n",
    "{\n",
    "   \"name\": \"add_to_shopping_cart\",\n",
    "   \"arguments\": {\n",
    "         \"items\": [\n",
    "            {\n",
    "               \"product_id\": \"123\",\n",
    "               \"quantity\": 1\n",
    "            },\n",
    "            {\n",
    "               \"product_id\": \"456\",\n",
    "               \"quantity\": 2\n",
    "            }\n",
    "         ],\n",
    "         \"user_id\": \"123\",\n",
    "         \"cart_id\": \"456\"\n",
    "   }\n",
    "}\n",
    "\n",
    "- Get shopping cart:\n",
    "{\n",
    "   \"name\": \"get_shopping_cart\",\n",
    "   \"arguments\": {\n",
    "         \"user_id\": \"123\",\n",
    "         \"cart_id\": \"456\"\n",
    "   }\n",
    "}\n",
    "\n",
    "After the tools are used you will get the outputs from the tools.\n",
    "\n",
    "Additional information:\n",
    "- User ID: {{ user_id }}\n",
    "- Cart ID: {{ cart_id }}\n",
    "\n",
    "CRITICAL RULES:\n",
    "- If tool_calls has values, final_answer MUST be false\n",
    "  (You cannot call tools and return to coordinator in the same response)\n",
    "- If final_answer is true, tool_calls MUST be []\n",
    "  (You must wait for tool results before returning to coordinator)\n",
    "- If you need tool results before answering, set:\n",
    "  tool_calls=[...], final_answer=false\n",
    "- After receiving tool results, you can then set:\n",
    "  tool_calls=[], final_answer=true\n",
    "\n",
    "Instructions:\n",
    "- Use names specificly provided in the available tools. Don't add any additional text to the names.\n",
    "- You can run multipple tools at once.\n",
    "- Once you get the tool results back, you might choose to performa additional tool calls.\n",
    "- Once your work is done, set final_answer to True, you should not suggest using more tools then.\n",
    "- As the final answer you should return an answer to the users query in a form of actions performed.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      available_tools=state.shopping_cart_available_tools,\n",
    "      user_id=state.user_id,\n",
    "      cart_id=state.cart_id\n",
    "   )\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for msg in messages:\n",
    "      conversation.append(lc_messages_to_regular_messages(msg))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=ShoppingCartAgentResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0,\n",
    "   )\n",
    "\n",
    "   if response.final_answer:\n",
    "      ai_message = AIMessage(\n",
    "         content=response.answer,\n",
    "      )\n",
    "   elif response.tool_calls:\n",
    "      tool_calls = []\n",
    "      for i, tc in enumerate(response.tool_calls):\n",
    "         tool_calls.append({\n",
    "               \"id\": f\"call_{i}\",\n",
    "               \"name\": tc.name,\n",
    "               \"args\": tc.arguments\n",
    "         })\n",
    "\n",
    "      ai_message = AIMessage(\n",
    "         content=response.answer,\n",
    "         tool_calls=tool_calls\n",
    "         )\n",
    "   else:\n",
    "      ai_message = AIMessage(\n",
    "         content=response.answer,\n",
    "      )\n",
    "\n",
    "   return {\n",
    "      \"messages\": [ai_message],\n",
    "      \"tool_calls\": response.tool_calls,\n",
    "      \"shopping_cart_iteration\": state.shopping_cart_iteration + 1,\n",
    "      \"answer\": response.answer,\n",
    "      \"shopping_cart_final_answer\": response.final_answer\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be362ed",
   "metadata": {},
   "source": [
    "### Coordinator Agent node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61982b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"coordinator_agent\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1\"}\n",
    ")\n",
    "def coordinator_agent_node(state) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are a Coordinator Agent as part of a shopping assistant.\n",
    "\n",
    "Your role is to create plans for solving user queries and delegate the tasks accordingly.\n",
    "You will be given a conversation history, your task is to create a plan for solving the user's query.\n",
    "After the plan is created, you should output the next agent to invoke and the task to be performed by that agent.\n",
    "Once an agent finishes its task, you will be handed the control back, you should then review the conversation history and revise the plan.\n",
    "If there is a sequence of tasks to be performed by a single agent, you should combine them into a single task.\n",
    "\n",
    "The possible agents are:\n",
    "\n",
    "- product_qa_agent: The user is asking a question about a product. This can be a question about available products, their specifications, user reviews etc.\n",
    "- shopping_cart_agent: The user is asking to add or remove items from the shopping cart or questions about the current shopping cart.\n",
    "\n",
    "CRITICAL RULES:\n",
    "- If next_agent is \"\", final_answer MUST be false\n",
    "  (You cannot delegate the task to an agent and return to the user in the same response)\n",
    "- If final_answer is true, next_agent MUST be \"\"\n",
    "  (You must wait for agent results before returning to user)\n",
    "- If you need to call other agents before answering, set:\n",
    "  next_agent=\"...\", final_answer=false\n",
    "- After receiving agent results, you can then set:\n",
    "  next_agent=\"\", final_answer=true\n",
    "\n",
    "Additional instructions:\n",
    "\n",
    "- Write the plan to the plan field.\n",
    "- Write the next agent to invoke to the next_agent field.\n",
    "- Once you have all the information needed to answer the user's query, you should set the final_answer field to True and output the answer to the user's query.\n",
    "- Never set final_answer to true if the plan is not complete.\n",
    "- You should output the next_agent field as well as the plan field.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render()\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for msg in messages:\n",
    "      conversation.append(lc_messages_to_regular_messages(msg))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=CoordinatorAgentResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0,\n",
    "   )\n",
    "\n",
    "   if response.final_answer:\n",
    "      ai_message = [AIMessage(\n",
    "         content=response.answer,\n",
    "      )]\n",
    "   else:\n",
    "      ai_message = []\n",
    "\n",
    "   return {\n",
    "      \"messages\": ai_message,\n",
    "      \"answer\": response.answer,\n",
    "      \"next_agent\": response.next_agent,\n",
    "      \"plan\": [data.model_dump() for data in response.plan],\n",
    "      \"coordinator_final_answer\": response.final_answer,\n",
    "      \"coordinator_iteration\": state.coordinator_iteration + 1\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3441856",
   "metadata": {},
   "source": [
    "### Product QA Agent Tool Use Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce06547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_qa_tool_router(state) -> str:\n",
    "    \"\"\"Decide whether to continue or end\"\"\"\n",
    "    \n",
    "    if state.product_qa_final_answer:\n",
    "        return \"end\"\n",
    "    elif state.product_qa_iteration > 3:\n",
    "        return \"end\"\n",
    "    elif len(state.mcp_tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadec086",
   "metadata": {},
   "source": [
    "### Shopping Cart Agent Tool Use Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shopping_cart_tool_router(state) -> str:\n",
    "    \"\"\"Decide whether to continue or end\"\"\"\n",
    "    \n",
    "    if state.shopping_cart_final_answer:\n",
    "        return \"end\"\n",
    "    elif state.shopping_cart_iteration > 3:\n",
    "        return \"end\"\n",
    "    elif len(state.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3fd74b",
   "metadata": {},
   "source": [
    "### Coordinator Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb1bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinator_router(state) -> str:\n",
    "    \"\"\"Decide whether to continue or end\"\"\"\n",
    "    \n",
    "    if state.coordinator_final_answer:\n",
    "        return \"end\"\n",
    "    elif state.coordinator_iteration > 4:\n",
    "        return \"end\"\n",
    "    elif state.next_agent == \"product_qa_agent\":\n",
    "        return \"product_qa_agent\"\n",
    "    elif state.next_agent == \"shopping_cart_agent\":\n",
    "        return \"shopping_cart_agent\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5025df65",
   "metadata": {},
   "source": [
    "### Custom tool node function that supports running tools exposed via MCP Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b60b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def mcp_tool_node(state) -> str:\n",
    "\n",
    "    tool_messages = []\n",
    "\n",
    "    for i, tc in enumerate(state.mcp_tool_calls):\n",
    "\n",
    "        client = Client(tc.server)\n",
    "\n",
    "        async with client:\n",
    "\n",
    "            result = await client.call_tool(tc.name, tc.arguments)\n",
    "\n",
    "            tool_message = ToolMessage(\n",
    "                content=result,\n",
    "                tool_call_id=f\"call_{i}\"\n",
    "            )\n",
    "\n",
    "            tool_messages.append(tool_message)\n",
    "\n",
    "    return {\n",
    "        \"messages\": tool_messages\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f5eb3",
   "metadata": {},
   "source": [
    "### LangGraph Grapg implementation with MCP support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shopping_cart_agent_tools = [add_to_shopping_cart, remove_from_cart, get_shopping_cart]\n",
    "shopping_cart_tool_node = ToolNode(shopping_cart_agent_tools)\n",
    "shopping_cart_tool_descriptions = get_tool_descriptions_from_node(shopping_cart_tool_node)\n",
    "\n",
    "mcp_servers = [\"http://localhost:8001/mcp\", \"http://localhost:8002/mcp\"]\n",
    "product_qa_tool_descriptions = await get_tool_descriptions_from_mcp_servers(mcp_servers)\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_edge(START, \"coordinator_agent_node\")\n",
    "\n",
    "workflow.add_node(\"shopping_cart_agent_node\", shopping_cart_agent_node)\n",
    "workflow.add_node(\"coordinator_agent_node\", coordinator_agent_node)\n",
    "workflow.add_node(\"product_qa_agent_node\", product_qa_agent_node)\n",
    "workflow.add_node(\"product_qa_tool_node\", mcp_tool_node)\n",
    "workflow.add_node(\"shopping_cart_tool_node\", shopping_cart_tool_node)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"coordinator_agent_node\",\n",
    "    coordinator_router,\n",
    "    {\n",
    "        \"product_qa_agent\": \"product_qa_agent_node\",\n",
    "        \"shopping_cart_agent\": \"shopping_cart_agent_node\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"product_qa_agent_node\",\n",
    "    product_qa_tool_router,\n",
    "    {\n",
    "        \"tools\": \"product_qa_tool_node\",\n",
    "        \"end\": \"coordinator_agent_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"shopping_cart_agent_node\",\n",
    "    shopping_cart_tool_router,\n",
    "    {\n",
    "        \"tools\": \"shopping_cart_tool_node\",\n",
    "        \"end\": \"coordinator_agent_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"product_qa_tool_node\", \"product_qa_agent_node\")\n",
    "workflow.add_edge(\"shopping_cart_tool_node\", \"shopping_cart_agent_node\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16a0566",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f9594e",
   "metadata": {},
   "source": [
    "### Example Graph Invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c6c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is the weather today?\"}],\n",
    "    \"user_id\": \"adlkfjdslkfgjs\",\n",
    "    \"cart_id\": \"afnvjenevjnjvev\",\n",
    "    \"product_qa_available_tools\": product_qa_tool_descriptions,\n",
    "    \"shopping_cart_available_tools\": shopping_cart_tool_descriptions\n",
    "}\n",
    "result = await graph.ainvoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4e9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd458ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Can I get earphones for myself, a laptop bag for my wife and something cool for my kids?\"}],\n",
    "    \"user_id\": \"adlkfjdslkfgjs\",\n",
    "    \"cart_id\": \"afnvjenevjnjvev\",\n",
    "    \"product_qa_available_tools\": product_qa_tool_descriptions,\n",
    "    \"shopping_cart_available_tools\": shopping_cart_tool_descriptions\n",
    "}\n",
    "result = await graph.ainvoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98336862",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab70928",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Can you add an item with ID B09NLTDHQ6 to my cart?\"}],\n",
    "    \"user_id\": \"adlkfjdslkfgjs\",\n",
    "    \"cart_id\": \"afnvjenevjnjvev\",\n",
    "    \"product_qa_available_tools\": product_qa_tool_descriptions,\n",
    "    \"shopping_cart_available_tools\": shopping_cart_tool_descriptions\n",
    "}\n",
    "result = await graph.ainvoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fa630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Can I get earphones for myself, a laptop bag for my wife and something cool for my kids? Can you also pick the items with the best user reviews and add them to my shopping cart?\"}],\n",
    "    \"user_id\": \"adlkfjdslkfgjs\",\n",
    "    \"cart_id\": \"afnvjenevjnjvev\",\n",
    "    \"product_qa_available_tools\": product_qa_tool_descriptions,\n",
    "    \"shopping_cart_available_tools\": shopping_cart_tool_descriptions\n",
    "}\n",
    "result = await graph.ainvoke(initial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
