{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57fdc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmcp import Client\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Prefetch, Filter, FieldCondition, MatchText, FusionQuery, MatchValue\n",
    "\n",
    "from langsmith import traceable, get_current_run_tree\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "from jinja2 import Template\n",
    "from typing import Literal, Dict, Any, Annotated, List, Optional\n",
    "from IPython.display import Image, display\n",
    "from operator import add\n",
    "from openai import OpenAI\n",
    "\n",
    "import openai\n",
    "\n",
    "import random\n",
    "import ast\n",
    "import inspect\n",
    "import instructor\n",
    "import json\n",
    "\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "from psycopg2.extras import RealDictCursor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb45461",
   "metadata": {},
   "source": [
    "### List available tools in MCP servers running on http://localhost:8001/mcp and http://localhost:8002/mcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9b8acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"http://localhost:8001/mcp\")\n",
    "\n",
    "async with client:\n",
    "    # List available resources\n",
    "    tools = await client.list_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8526333",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf2bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tools[0].name)\n",
    "print(tools[0].description)\n",
    "print(tools[0].inputSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6511d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"http://localhost:8002/mcp\")\n",
    "\n",
    "async with client:\n",
    "    # List available resources\n",
    "    tools = await client.list_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d7b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tools[0].name)\n",
    "print(tools[0].description)\n",
    "print(tools[0].inputSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53905264",
   "metadata": {},
   "source": [
    "### Execute a tool on one of the running MCP Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3943bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"http://localhost:8001/mcp\")\n",
    "\n",
    "async with client:\n",
    "    # List available resources\n",
    "    result = await client.call_tool(\"get_formatted_item_context\", {\"query\": \"earphones\", \"top_k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1ab670",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee90198",
   "metadata": {},
   "source": [
    "### A function to extract tool definitions of all available tools in provided MCP servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c38759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_docstring_params(docstring: str) -> Dict[str, str]:\n",
    "    \"\"\"Extract parameter descriptions from docstring (handles both Args: and Parameters: formats).\"\"\"\n",
    "    params = {}\n",
    "    lines = docstring.split('\\n')\n",
    "    in_params = False\n",
    "    current_param = None\n",
    "    \n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        \n",
    "        # Check for parameter section start\n",
    "        if stripped in ['Args:', 'Arguments:', 'Parameters:', 'Params:']:\n",
    "            in_params = True\n",
    "            current_param = None\n",
    "        elif stripped.startswith('Returns:') or stripped.startswith('Raises:'):\n",
    "            in_params = False\n",
    "        elif in_params:\n",
    "            # Parse parameter line (handles \"param: desc\" and \"- param: desc\" formats)\n",
    "            if ':' in stripped and (stripped[0].isalpha() or stripped.startswith(('-', '*'))):\n",
    "                param_name = stripped.lstrip('- *').split(':')[0].strip()\n",
    "                param_desc = ':'.join(stripped.lstrip('- *').split(':')[1:]).strip()\n",
    "                params[param_name] = param_desc\n",
    "                current_param = param_name\n",
    "            elif current_param and stripped:\n",
    "                # Continuation of previous parameter description\n",
    "                params[current_param] += ' ' + stripped\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78593a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_tool_descriptions_from_mcp_servers(mcp_servers: list[str]) -> list[dict]:\n",
    "\n",
    "    tool_descriptions = []\n",
    "\n",
    "    for server in mcp_servers:\n",
    "\n",
    "        client = Client(server)\n",
    "\n",
    "        async with client:\n",
    "\n",
    "            tools = await client.list_tools()\n",
    "\n",
    "            for tool in tools:\n",
    "                \n",
    "                result = {\n",
    "                    \"name\": \"\",\n",
    "                    \"description\": \"\",\n",
    "                    \"parameters\": {\"type\": \"object\", \"properties\": {}},\n",
    "                    \"required\": [],\n",
    "                    \"returns\": {\"type\": \"string\", \"description\": \"\"},\n",
    "                    \"server\": server\n",
    "                }\n",
    "\n",
    "                result[\"name\"] = tool.name\n",
    "                result[\"required\"] = tool.inputSchema.get(\"required\", [])\n",
    "\n",
    "                ## Get Description\n",
    "\n",
    "                description = tool.description.split(\"\\n\\n\")[0]\n",
    "                result[\"description\"] = description\n",
    "\n",
    "\n",
    "                ## Get Returns\n",
    "\n",
    "                returns = tool.description.split(\"Returns:\")[1].strip()\n",
    "                result[\"returns\"][\"description\"] = returns\n",
    "\n",
    "                ## Get parameters\n",
    "\n",
    "                property_descriptions = parse_docstring_params(tool.description)\n",
    "                properties = tool.inputSchema.get(\"properties\", {})\n",
    "                for key, value in properties.items():\n",
    "                    properties[key][\"description\"] = property_descriptions.get(key, \"\")\n",
    "\n",
    "                result[\"parameters\"][\"properties\"] = properties\n",
    "\n",
    "                tool_descriptions.append(result)\n",
    "\n",
    "    return tool_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b70d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_servers = [\"http://localhost:8001/mcp\", \"http://localhost:8002/mcp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e6879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_descriptions = await get_tool_descriptions_from_mcp_servers(mcp_servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c781b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2beecc8",
   "metadata": {},
   "source": [
    "## Agent integration with tools exposed via MCP Servers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d9791",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad134143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lc_messages_to_regular_messages(msg):\n",
    "\n",
    "    if isinstance(msg, dict):\n",
    "        \n",
    "        if msg.get(\"role\") == \"user\":\n",
    "            return {\"role\": \"user\", \"content\": msg[\"content\"]}\n",
    "        elif msg.get(\"role\") == \"assistant\":\n",
    "            return {\"role\": \"assistant\", \"content\": msg[\"content\"]}\n",
    "        elif msg.get(\"role\") == \"tool\":\n",
    "            return {\n",
    "                \"role\": \"tool\", \n",
    "                \"content\": msg[\"content\"], \n",
    "                \"tool_call_id\": msg.get(\"tool_call_id\")\n",
    "            }\n",
    "        \n",
    "    elif isinstance(msg, AIMessage):\n",
    "\n",
    "        result = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": msg.content\n",
    "        }\n",
    "        \n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls and len(msg.tool_calls) > 0 and not msg.tool_calls[0].get(\"name\").startswith(\"functions.\"):\n",
    "            result[\"tool_calls\"] = [\n",
    "                {\n",
    "                    \"id\": tc[\"id\"],\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tc[\"name\"].replace(\"functions.\", \"\"),\n",
    "                        \"arguments\": json.dumps(tc[\"args\"])\n",
    "                    }\n",
    "                }\n",
    "                for tc in msg.tool_calls\n",
    "            ]\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    elif isinstance(msg, ToolMessage):\n",
    "\n",
    "        return {\"role\": \"tool\", \"content\": msg.content, \"tool_call_id\": msg.tool_call_id}\n",
    "    \n",
    "    else:\n",
    "\n",
    "        return {\"role\": \"user\", \"content\": str(msg)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a386b",
   "metadata": {},
   "source": [
    "### The Product QA Agent Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "    server: str\n",
    "\n",
    "class RAGUsedContext(BaseModel):\n",
    "    id: int\n",
    "    description: str\n",
    "\n",
    "class ProductQAAgentResponse(BaseModel):\n",
    "    answer: str\n",
    "    tool_calls: List[MCPToolCall] = Field(default_factory=list)\n",
    "    final_answer: bool = Field(default=False)\n",
    "    retrieved_context_ids: List[RAGUsedContext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9bbb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentRouterAgentResponse(BaseModel):\n",
    "    user_intent: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964890f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "\n",
    "class ShoppingCartAgentResponse(BaseModel):\n",
    "    answer: str\n",
    "    tool_calls: List[ToolCall] = Field(default_factory=list)\n",
    "    final_answer: bool = Field(default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301a2b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(BaseModel):\n",
    "    messages: Annotated[List[Any], add] = []\n",
    "    answer: str = \"\"\n",
    "    product_qa_iteration: int = Field(default=0)\n",
    "    shopping_cart_iteration: int = Field(default=0)\n",
    "    final_answer: bool = Field(default=False)\n",
    "    product_qa_available_tools: List[Dict[str, Any]] = []\n",
    "    shopping_cart_available_tools: List[Dict[str, Any]] = []\n",
    "    mcp_tool_calls: Optional[List[MCPToolCall]] = Field(default_factory=list)\n",
    "    tool_calls: Optional[List[ToolCall]] = Field(default_factory=list)\n",
    "    retrieved_context_ids: List[RAGUsedContext] = Field(default_factory=list)\n",
    "    user_intent: str = \"\"\n",
    "    user_id: str = \"\"\n",
    "    cart_id: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a994738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"product_qa_agent\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1\"}\n",
    ")\n",
    "def product_qa_agent_node(state: State) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are a shopping assistant that can answer questions about the products in stock.\n",
    "\n",
    "You will be given a question and a list of tools you can use to answer that question.\n",
    "\n",
    "<Available tools>\n",
    "{{ available_tools | tojson }}\n",
    "</Available tools>\n",
    "\n",
    "After the tools are used you will get the outputs from the tools.\n",
    "\n",
    "When you need to use a tool, format your response as:\n",
    "\n",
    "<tool_call>\n",
    "{\"name\": \"tool_name\", \"arguments\": {...}}\n",
    "</tool_call>\n",
    "\n",
    "Use names specificly provided in the available tools. Don't add any additional text to the names.\n",
    "\n",
    "You should tend to use tools when additional information is needed to answer the question.\n",
    "\n",
    "If you set final_answer to True, you should not use any tools.\n",
    "\n",
    "Instructions:\n",
    "- You need to answer the question based on the retrieved context using the available tools only.\n",
    "- Never use word context and refer to it as the available products.\n",
    "- You should only answer questions about the products in stock. If the question is not about the products in stock, you should ask for clarification.\n",
    "- As a final output you need to provide:\n",
    "\n",
    "* The answer to the question based on the retrieved context.\n",
    "* The list of the indexes from the chunks returned from all tool calls that were used to answer the question. If more than one chunk was used to compile the answer from a single tool call, be sure to return all of them.\n",
    "* Short description of the item based on the retrieved context.\n",
    "\n",
    "- The answer to the question should contain detailed information about the product and returned with detailed specification in bullet points.\n",
    "- The short description should have the name of the item.\n",
    "- If the user's request requires using a tool, set tool_calls with the appropriate function name and arguments.\n",
    "- If you have all the information needed to provide a complete answer, set final_answer to True.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      available_tools=state.product_qa_available_tools\n",
    "   )\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for msg in messages:\n",
    "      conversation.append(lc_messages_to_regular_messages(msg))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=ProductQAAgentResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0,\n",
    "   )\n",
    "\n",
    "   if response.tool_calls:\n",
    "      tool_calls = []\n",
    "      for i, tc in enumerate(response.tool_calls):\n",
    "         tool_calls.append({\n",
    "               \"id\": f\"call_{i}\",\n",
    "               \"name\": tc.name,\n",
    "               \"args\": tc.arguments\n",
    "         })\n",
    "\n",
    "      ai_message = AIMessage(\n",
    "         content=response.answer,\n",
    "         tool_calls=tool_calls\n",
    "         )\n",
    "   else:\n",
    "      ai_message = AIMessage(\n",
    "         content=response.answer,\n",
    "      )\n",
    "\n",
    "   return {\n",
    "      \"messages\": [ai_message],\n",
    "      \"mcp_tool_calls\": response.tool_calls,\n",
    "      \"product_qa_iteration\": state.product_qa_iteration + 1,\n",
    "      \"answer\": response.answer,\n",
    "      \"final_answer\": response.final_answer,\n",
    "      \"retrieved_context_ids\": response.retrieved_context_ids\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be362ed",
   "metadata": {},
   "source": [
    "### User Intent Router node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61982b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"intent_router_agent\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1\"}\n",
    ")\n",
    "def intent_router_agent_node(state) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are a part of a shopping assistant that routes user queries to the appropriate agents.\n",
    "\n",
    "You will be given a conversation history, your task is to classify the intent of the user's latest query and output an appropriate classification.\n",
    "\n",
    "The possible intents are:\n",
    "\n",
    "- product_qa: The user is asking a question about a product. This can be a question about available products, their specifications, user reviews etc.\n",
    "- shopping_cart: The user is asking to add or remove items from the shopping cart or questions about the current shopping cart.\n",
    "- other: The user's latest query is not clear or not related to the shopping assistant.\n",
    "\n",
    "Additional instructions:\n",
    "\n",
    "- Write the intent classification to the user_intent field.\n",
    "- If there is not enough context in the conversation history about the actions needed to be performed, do not classify as 'shopping_cart', instead classify as 'other'.\n",
    "- If the classification is 'other', you should output the answer to the user's query trying to clarify the user's intent.\n",
    "- If the classification is 'product_qa' or 'shopping_cart', you should only output the intent classification and no other text.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render()\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for msg in messages:\n",
    "      conversation.append(lc_messages_to_regular_messages(msg))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=IntentRouterAgentResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0,\n",
    "   )\n",
    "\n",
    "   if response.user_intent == \"product_qa\":\n",
    "      ai_message = []\n",
    "   else:\n",
    "      ai_message = [AIMessage(\n",
    "         content=response.answer,\n",
    "      )]\n",
    "\n",
    "   return {\n",
    "      \"messages\": ai_message,\n",
    "      \"answer\": response.answer,\n",
    "      \"user_intent\": response.user_intent\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b73f2f5",
   "metadata": {},
   "source": [
    "### The Shopping Cart Agent Node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818465b9",
   "metadata": {},
   "source": [
    "#### Write to shopping cart tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91516007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_shopping_cart(items: list[dict], user_id: str, cart_id: str) -> str:\n",
    "\n",
    "    \"\"\"Add a list of provided items to the shopping cart.\n",
    "    \n",
    "    Args:\n",
    "        items: A list of items to add to the shopping cart. Each item is a dictionary with the following keys: product_id, quantity.\n",
    "        user_id: The id of the user to add the items to the shopping cart.\n",
    "        cart_id: The id of the shopping cart to add the items to.\n",
    "        \n",
    "    Returns:\n",
    "        A list of the items added to the shopping cart.\n",
    "    \"\"\"\n",
    "\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=5433,\n",
    "        database=\"langgraph_db\",\n",
    "        user=\"langgraph_user\",\n",
    "        password=\"langgraph_password\"\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "\n",
    "    with conn.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "        \n",
    "        for item in items:\n",
    "            product_id = item['product_id']\n",
    "            quantity = item['quantity']\n",
    "\n",
    "            qdrant_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "            dummy_vector = np.zeros(1536).tolist()\n",
    "            payload = qdrant_client.query_points(\n",
    "                collection_name=\"Amazon-items-collection-02-items\",\n",
    "                query=dummy_vector,\n",
    "                query_filter=Filter(\n",
    "                    must=[\n",
    "                        FieldCondition(\n",
    "                            key=\"parent_asin\",\n",
    "                            match=MatchValue(value=product_id)\n",
    "                        )\n",
    "                    ]\n",
    "                ),\n",
    "                with_payload=True,\n",
    "                limit=1\n",
    "            ).points[0].payload\n",
    "\n",
    "            product_image_url = payload.get(\"first_large_image\")\n",
    "            price = payload.get(\"price\")\n",
    "            currency = 'USD'\n",
    "        \n",
    "            # Check if item already exists\n",
    "            check_query = \"\"\"\n",
    "                SELECT id, quantity, price \n",
    "                FROM shopping_carts.shopping_cart_items \n",
    "                WHERE user_id = %s AND shopping_cart_id = %s AND product_id = %s\n",
    "            \"\"\"\n",
    "            cursor.execute(check_query, (user_id, cart_id, product_id))\n",
    "            existing_item = cursor.fetchone()\n",
    "            \n",
    "            if existing_item:\n",
    "                # Update existing item\n",
    "                new_quantity = existing_item['quantity'] + quantity\n",
    "                \n",
    "                update_query = \"\"\"\n",
    "                    UPDATE shopping_carts.shopping_cart_items \n",
    "                    SET \n",
    "                        quantity = %s,\n",
    "                        price = %s,\n",
    "                        currency = %s,\n",
    "                        product_image_url = COALESCE(%s, product_image_url)\n",
    "                    WHERE user_id = %s AND shopping_cart_id = %s AND product_id = %s\n",
    "                    RETURNING id, quantity, price\n",
    "                \"\"\"\n",
    "                \n",
    "                cursor.execute(update_query, (new_quantity, price, currency, product_image_url, user_id, cart_id, product_id))\n",
    "            \n",
    "            else:\n",
    "                # Insert new item\n",
    "                insert_query = \"\"\"\n",
    "                    INSERT INTO shopping_carts.shopping_cart_items (\n",
    "                        user_id, shopping_cart_id, product_id,\n",
    "                        price, quantity, currency, product_image_url\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "                    RETURNING id, quantity, price\n",
    "                \"\"\"\n",
    "                \n",
    "                cursor.execute(insert_query, (user_id, cart_id, product_id, price, quantity, currency, product_image_url))\n",
    "            \n",
    "    return f\"Added {items} to the shopping cart.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2348676e",
   "metadata": {},
   "source": [
    "#### Get the shopping cart tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b024a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shopping_cart(user_id: str, cart_id: str) -> list[dict]:\n",
    "\n",
    "    \"\"\"\n",
    "    Retrieve all items in a user's shopping cart.\n",
    "    \n",
    "    Args:\n",
    "        user_id: User ID\n",
    "        shopping_cart_id: Cart identifier\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing cart items\n",
    "    \"\"\"\n",
    "    \n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=5433,\n",
    "        database=\"langgraph_db\",\n",
    "        user=\"langgraph_user\",\n",
    "        password=\"langgraph_password\"\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "\n",
    "    with conn.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "\n",
    "        query = \"\"\"\n",
    "                SELECT \n",
    "                    product_id, price, quantity,\n",
    "                    currency, product_image_url,\n",
    "                    (price * quantity) as total_price\n",
    "                FROM shopping_carts.shopping_cart_items \n",
    "                WHERE user_id = %s AND shopping_cart_id = %s\n",
    "                ORDER BY added_at DESC\n",
    "            \"\"\"\n",
    "        cursor.execute(query, (user_id, cart_id))\n",
    "\n",
    "        return [dict(row) for row in cursor.fetchall()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37520a65",
   "metadata": {},
   "source": [
    "#### Delete from shopping cart tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d6cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_from_cart(product_id: str, user_id: str, cart_id: str) -> str:\n",
    "\n",
    "    \"\"\"\n",
    "    Remove an item completely from the shopping cart.\n",
    "    \n",
    "    Args:\n",
    "        user_id: User ID\n",
    "        product_id: Product ID to remove\n",
    "        shopping_cart_id: Cart identifier\n",
    "    \n",
    "    Returns:\n",
    "        True if item was removed, False if item wasn't found\n",
    "    \"\"\"\n",
    "    \n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=5433,\n",
    "        database=\"langgraph_db\",\n",
    "        user=\"langgraph_user\",\n",
    "        password=\"langgraph_password\"\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "\n",
    "    with conn.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "\n",
    "        query = \"\"\"\n",
    "                DELETE FROM shopping_carts.shopping_cart_items\n",
    "                WHERE user_id = %s AND shopping_cart_id = %s AND product_id = %s\n",
    "            \"\"\"\n",
    "        cursor.execute(query, (user_id, cart_id, product_id))\n",
    "\n",
    "        return cursor.rowcount > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575ccea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"shopping_cart_agent\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1\"}\n",
    ")\n",
    "def shopping_cart_agent_node(state) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are a part of the shopping assistant that can manage the user's shopping cart.\n",
    "\n",
    "You will be given a conversation history and a list of tools, your task is to perform the action requested by the latest user query.\n",
    "\n",
    "<Available tools>\n",
    "{{ available_tools | tojson }}\n",
    "</Available tools>\n",
    "\n",
    "After the tools are used you will get the outputs from the tools.\n",
    "\n",
    "When you need to use a tool, format your response as:\n",
    "\n",
    "<tool_call>\n",
    "{\"name\": \"tool_name\", \"arguments\": {...}}\n",
    "</tool_call>\n",
    "\n",
    "Additional information:\n",
    "- User ID: {{ user_id }}\n",
    "- Cart ID: {{ cart_id }}\n",
    "\n",
    "Instructions:\n",
    "- Use names specificly provided in the available tools. Don't add any additional text to the names.\n",
    "- You can run multipple tools at once.\n",
    "- Once you get the tool results back, you might choose to performa additional tool calls.\n",
    "- Once your work is done, set final_answer to True, you should not suggest using more tools then.\n",
    "- As the final answer you should return an answer to the users query in a form of actions performed.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      available_tools=state.shopping_cart_available_tools,\n",
    "      user_id=state.user_id,\n",
    "      cart_id=state.cart_id\n",
    "   )\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for msg in messages:\n",
    "      conversation.append(lc_messages_to_regular_messages(msg))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=ShoppingCartAgentResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0,\n",
    "   )\n",
    "\n",
    "   if response.tool_calls:\n",
    "      tool_calls = []\n",
    "      for i, tc in enumerate(response.tool_calls):\n",
    "         tool_calls.append({\n",
    "               \"id\": f\"call_{i}\",\n",
    "               \"name\": tc.name,\n",
    "               \"args\": tc.arguments\n",
    "         })\n",
    "\n",
    "      ai_message = AIMessage(\n",
    "         content=response.answer,\n",
    "         tool_calls=tool_calls\n",
    "         )\n",
    "   else:\n",
    "      ai_message = AIMessage(\n",
    "         content=response.answer,\n",
    "      )\n",
    "\n",
    "   return {\n",
    "      \"messages\": [ai_message],\n",
    "      \"tool_calls\": response.tool_calls,\n",
    "      \"shopping_cart_iteration\": state.shopping_cart_iteration + 1,\n",
    "      \"answer\": response.answer,\n",
    "      \"final_answer\": response.final_answer\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3441856",
   "metadata": {},
   "source": [
    "### Product QA Agent Tool Use Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce06547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_qa_tool_router(state) -> str:\n",
    "    \"\"\"Decide whether to continue or end\"\"\"\n",
    "    \n",
    "    if state.final_answer:\n",
    "        return \"end\"\n",
    "    elif state.product_qa_iteration > 2:\n",
    "        return \"end\"\n",
    "    elif len(state.mcp_tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadec086",
   "metadata": {},
   "source": [
    "### Shopping Cart Agent Tool Use Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shopping_cart_tool_router(state) -> str:\n",
    "    \"\"\"Decide whether to continue or end\"\"\"\n",
    "    \n",
    "    if state.final_answer:\n",
    "        return \"end\"\n",
    "    elif state.shopping_cart_iteration > 2:\n",
    "        return \"end\"\n",
    "    elif len(state.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3fd74b",
   "metadata": {},
   "source": [
    "### User Intent Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb1bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_intent_router(state) -> str:\n",
    "    \"\"\"Decide whether to continue or end\"\"\"\n",
    "    \n",
    "    if state.user_intent == \"product_qa\":\n",
    "        return \"product_qa_agent\"\n",
    "    elif state.user_intent == \"shopping_cart\":\n",
    "        return \"shopping_cart_agent\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5025df65",
   "metadata": {},
   "source": [
    "### Custom tool node function that supports running tools exposed via MCP Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b60b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def mcp_tool_node(state) -> str:\n",
    "\n",
    "    tool_messages = []\n",
    "\n",
    "    for i, tc in enumerate(state.mcp_tool_calls):\n",
    "\n",
    "        client = Client(tc.server)\n",
    "\n",
    "        async with client:\n",
    "\n",
    "            result = await client.call_tool(tc.name, tc.arguments)\n",
    "\n",
    "            tool_message = ToolMessage(\n",
    "                content=result,\n",
    "                tool_call_id=f\"call_{i}\"\n",
    "            )\n",
    "\n",
    "            tool_messages.append(tool_message)\n",
    "\n",
    "    return {\n",
    "        \"messages\": tool_messages\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f5eb3",
   "metadata": {},
   "source": [
    "### LangGraph Grapg implementation with MCP support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shopping_cart_agent_tools = [add_to_shopping_cart, remove_from_cart, get_shopping_cart]\n",
    "shopping_cart_tool_node = ToolNode(shopping_cart_agent_tools)\n",
    "shopping_cart_tool_descriptions = get_tool_descriptions_from_node(shopping_cart_tool_node)\n",
    "\n",
    "mcp_servers = [\"http://localhost:8001/mcp\", \"http://localhost:8002/mcp\"]\n",
    "product_qa_tool_descriptions = await get_tool_descriptions_from_mcp_servers(mcp_servers)\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_edge(START, \"intent_router_agent_node\")\n",
    "\n",
    "workflow.add_node(\"shopping_cart_agent_node\", shopping_cart_agent_node)\n",
    "workflow.add_node(\"intent_router_agent_node\", intent_router_agent_node)\n",
    "workflow.add_node(\"product_qa_agent_node\", product_qa_agent_node)\n",
    "workflow.add_node(\"product_qa_tool_node\", mcp_tool_node)\n",
    "workflow.add_node(\"shopping_cart_tool_node\", shopping_cart_tool_node)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"intent_router_agent_node\",\n",
    "    user_intent_router,\n",
    "    {\n",
    "        \"product_qa_agent\": \"product_qa_agent_node\",\n",
    "        \"shopping_cart_agent\": \"shopping_cart_agent_node\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"product_qa_agent_node\",\n",
    "    product_qa_tool_router,\n",
    "    {\n",
    "        \"tools\": \"product_qa_tool_node\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"shopping_cart_agent_node\",\n",
    "    shopping_cart_tool_router,\n",
    "    {\n",
    "        \"tools\": \"shopping_cart_tool_node\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"product_qa_tool_node\", \"product_qa_agent_node\")\n",
    "workflow.add_edge(\"shopping_cart_tool_node\", \"shopping_cart_agent_node\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16a0566",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f9594e",
   "metadata": {},
   "source": [
    "### Invoke the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c6c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is the weather today?\"}],\n",
    "    \"user_id\": \"adlkfjdslkfgjs\",\n",
    "    \"cart_id\": \"afnvjenevjnjvev\",\n",
    "    \"product_qa_available_tools\": product_qa_tool_descriptions,\n",
    "    \"shopping_cart_available_tools\": shopping_cart_tool_descriptions\n",
    "}\n",
    "result = await graph.ainvoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4e9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd458ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Can I get earphones for myself, a laptop bag for my wife and something cool for my kids?\"}],\n",
    "    \"user_id\": \"adlkfjdslkfgjs\",\n",
    "    \"cart_id\": \"afnvjenevjnjvev\",\n",
    "    \"product_qa_available_tools\": product_qa_tool_descriptions,\n",
    "    \"shopping_cart_available_tools\": shopping_cart_tool_descriptions\n",
    "}\n",
    "result = await graph.ainvoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98336862",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab70928",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Can you add an item with ID B09NLTDHQ6 to my cart?\"}],\n",
    "    \"user_id\": \"adlkfjdslkfgjs\",\n",
    "    \"cart_id\": \"afnvjenevjnjvev\",\n",
    "    \"product_qa_available_tools\": product_qa_tool_descriptions,\n",
    "    \"shopping_cart_available_tools\": shopping_cart_tool_descriptions\n",
    "}\n",
    "result = await graph.ainvoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fa630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c004da0",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0854bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function_definition(function_def: str) -> Dict[str, Any]:\n",
    "    \"\"\"Parse a function definition string to extract metadata including type hints.\"\"\"\n",
    "    result = {\n",
    "        \"name\": \"\",\n",
    "        \"description\": \"\",\n",
    "        \"parameters\": {\"type\": \"object\", \"properties\": {}},\n",
    "        \"required\": [],\n",
    "        \"returns\": {\"type\": \"string\", \"description\": \"\"}\n",
    "    }\n",
    "    \n",
    "    # Parse the function using AST\n",
    "    tree = ast.parse(function_def.strip())\n",
    "    if not tree.body or not isinstance(tree.body[0], ast.FunctionDef):\n",
    "        return result\n",
    "        \n",
    "    func = tree.body[0]\n",
    "    result[\"name\"] = func.name\n",
    "    \n",
    "    # Extract docstring\n",
    "    docstring = ast.get_docstring(func) or \"\"\n",
    "    if docstring:\n",
    "        # Extract description (first line/paragraph)\n",
    "        desc_end = docstring.find('\\n\\n') if '\\n\\n' in docstring else docstring.find('\\nArgs:')\n",
    "        desc_end = desc_end if desc_end > 0 else docstring.find('\\nParameters:')\n",
    "        result[\"description\"] = docstring[:desc_end].strip() if desc_end > 0 else docstring.strip()\n",
    "        \n",
    "        # Parse parameter descriptions\n",
    "        param_descs = parse_docstring_params(docstring)\n",
    "        \n",
    "        # Extract return description\n",
    "        if \"Returns:\" in docstring:\n",
    "            result[\"returns\"][\"description\"] = docstring.split(\"Returns:\")[1].strip().split('\\n')[0]\n",
    "    \n",
    "    # Extract parameters with type hints\n",
    "    args = func.args\n",
    "    defaults = args.defaults\n",
    "    num_args = len(args.args)\n",
    "    num_defaults = len(defaults)\n",
    "    \n",
    "    for i, arg in enumerate(args.args):\n",
    "        if arg.arg == 'self':\n",
    "            continue\n",
    "            \n",
    "        param_info = {\n",
    "            \"type\": get_type_from_annotation(arg.annotation) if arg.annotation else \"string\",\n",
    "            \"description\": param_descs.get(arg.arg, \"\")\n",
    "        }\n",
    "        \n",
    "        # Check for default value\n",
    "        default_idx = i - (num_args - num_defaults)\n",
    "        if default_idx >= 0:\n",
    "            param_info[\"default\"] = ast.literal_eval(ast.unparse(defaults[default_idx]))\n",
    "        else:\n",
    "            result[\"required\"].append(arg.arg)\n",
    "        \n",
    "        result[\"parameters\"][\"properties\"][arg.arg] = param_info\n",
    "    \n",
    "    # Extract return type\n",
    "    if func.returns:\n",
    "        result[\"returns\"][\"type\"] = get_type_from_annotation(func.returns)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def get_type_from_annotation(annotation) -> str:\n",
    "    \"\"\"Convert AST annotation to type string.\"\"\"\n",
    "    if not annotation:\n",
    "        return \"string\"\n",
    "    \n",
    "    type_map = {\n",
    "        'str': 'string',\n",
    "        'int': 'integer', \n",
    "        'float': 'number',\n",
    "        'bool': 'boolean',\n",
    "        'list': 'array',\n",
    "        'dict': 'object',\n",
    "        'List': 'array',\n",
    "        'Dict': 'object'\n",
    "    }\n",
    "    \n",
    "    if isinstance(annotation, ast.Name):\n",
    "        return type_map.get(annotation.id, annotation.id)\n",
    "    elif isinstance(annotation, ast.Subscript) and isinstance(annotation.value, ast.Name):\n",
    "        base_type = annotation.value.id\n",
    "        return type_map.get(base_type, base_type.lower())\n",
    "    \n",
    "    return \"string\"\n",
    "\n",
    "\n",
    "def parse_docstring_params(docstring: str) -> Dict[str, str]:\n",
    "    \"\"\"Extract parameter descriptions from docstring (handles both Args: and Parameters: formats).\"\"\"\n",
    "    params = {}\n",
    "    lines = docstring.split('\\n')\n",
    "    in_params = False\n",
    "    current_param = None\n",
    "    \n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        \n",
    "        # Check for parameter section start\n",
    "        if stripped in ['Args:', 'Arguments:', 'Parameters:', 'Params:']:\n",
    "            in_params = True\n",
    "            current_param = None\n",
    "        elif stripped.startswith('Returns:') or stripped.startswith('Raises:'):\n",
    "            in_params = False\n",
    "        elif in_params:\n",
    "            # Parse parameter line (handles \"param: desc\" and \"- param: desc\" formats)\n",
    "            if ':' in stripped and (stripped[0].isalpha() or stripped.startswith(('-', '*'))):\n",
    "                param_name = stripped.lstrip('- *').split(':')[0].strip()\n",
    "                param_desc = ':'.join(stripped.lstrip('- *').split(':')[1:]).strip()\n",
    "                params[param_name] = param_desc\n",
    "                current_param = param_name\n",
    "            elif current_param and stripped:\n",
    "                # Continuation of previous parameter description\n",
    "                params[current_param] += ' ' + stripped\n",
    "    \n",
    "    return params\n",
    "\n",
    "\n",
    "def get_tool_descriptions_from_node(tool_node):\n",
    "    \"\"\"Extract tool descriptions from the ToolNode object.\"\"\"\n",
    "    descriptions = []\n",
    "    \n",
    "    if hasattr(tool_node, 'tools_by_name'):\n",
    "        tools_by_name = tool_node.tools_by_name\n",
    "        \n",
    "        for tool_name, tool in tools_by_name.items():\n",
    "            function_string = inspect.getsource(globals()[tool_name])\n",
    "            # function_string = inspect.getsource(getattr(tool_name))\n",
    "            result = parse_function_definition(function_string)\n",
    "\n",
    "            if result:\n",
    "                descriptions.append(result)\n",
    "    \n",
    "    return descriptions if descriptions else \"Could not extract tool descriptions\"\n",
    "\n",
    "\n",
    "def lc_messages_to_regular_messages(msg):\n",
    "\n",
    "    if isinstance(msg, dict):\n",
    "        \n",
    "        if msg.get(\"role\") == \"user\":\n",
    "            return {\"role\": \"user\", \"content\": msg[\"content\"]}\n",
    "        elif msg.get(\"role\") == \"assistant\":\n",
    "            return {\"role\": \"assistant\", \"content\": msg[\"content\"]}\n",
    "        elif msg.get(\"role\") == \"tool\":\n",
    "            return {\n",
    "                \"role\": \"tool\", \n",
    "                \"content\": msg[\"content\"], \n",
    "                \"tool_call_id\": msg.get(\"tool_call_id\")\n",
    "            }\n",
    "        \n",
    "    elif isinstance(msg, AIMessage):\n",
    "\n",
    "        result = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": msg.content\n",
    "        }\n",
    "        \n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls and len(msg.tool_calls) > 0 and not msg.tool_calls[0].get(\"name\").startswith(\"functions.\"):\n",
    "            result[\"tool_calls\"] = [\n",
    "                {\n",
    "                    \"id\": tc[\"id\"],\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tc[\"name\"].replace(\"functions.\", \"\"),\n",
    "                        \"arguments\": json.dumps(tc[\"args\"])\n",
    "                    }\n",
    "                }\n",
    "                for tc in msg.tool_calls\n",
    "            ]\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    elif isinstance(msg, ToolMessage):\n",
    "\n",
    "        return {\"role\": \"tool\", \"content\": msg.content, \"tool_call_id\": msg.tool_call_id}\n",
    "    \n",
    "    else:\n",
    "\n",
    "        return {\"role\": \"user\", \"content\": str(msg)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3898ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
