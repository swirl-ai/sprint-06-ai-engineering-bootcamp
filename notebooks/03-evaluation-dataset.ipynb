{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "\n",
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the sampled dataset with Amazon inventory metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = pd.read_json(\"../data/meta_Electronics_2022_2023_with_category_ratings_100_sample_1000.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate title and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(row):\n",
    "    return f\"{row['title']} {' '.join(row['features'])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items[\"preprocessed_data\"] = df_items.apply(preprocess_data, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate Qdrant client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=\"Amazon-items-collection-02\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample 50 items from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_items.sample(n=50, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the embeddings function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    response = openai.embeddings.create(\n",
    "        input=[text],\n",
    "        model=model,\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_embed = df_sample[\"preprocessed_data\"].tolist()\n",
    "pointstructs = []\n",
    "for i, data in enumerate(data_to_embed):\n",
    "    embedding = get_embedding(data)\n",
    "    pointstructs.append(\n",
    "        PointStruct(\n",
    "            id=i,\n",
    "            vector=embedding,\n",
    "            payload={\"text\": data},\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write embedded data to Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client.upsert(\n",
    "    collection_name=\"Amazon-items-collection-02\",\n",
    "    wait=True,\n",
    "    points=pointstructs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Render a prompt to generate synthetic Eval reference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "output_schema = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Suggested question.\",\n",
    "            },\n",
    "            \"chunk_ids\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Index of the chunk that could be used to answer the question.\",\n",
    "                },\n",
    "            },\n",
    "            \"answer_example\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Suggested answer grounded in the contexr.\",\n",
    "            },\n",
    "            \"reasoning\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Reasoning why the question could be answered with the chunks.\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = f\"\"\"\n",
    "I am building a RAG application. I have a collection of 50 chunks of text.\n",
    "The RAG application will act as a shopping assistant that can answer questions about the stock of the products we have available.\n",
    "I will provide all of the available products to you with indexes of each chunk.\n",
    "I want you to come up with 30 questions to which the answers could be grounded in the chunk context.\n",
    "As an output I need you to provide me the list of questions and the indexes of the chunks that could be used to answer them.\n",
    "Also, provide an example answer to the question given the context of the chunks.\n",
    "Also, provide the reason why you chose the chunks to answer the questions.\n",
    "Try to have a mix of questions that could use multipple chunks and questions that could use single chunk.\n",
    "Also, include 5 questions that can't be answered with the available chunks.\n",
    "\n",
    "<OUTPUT JSON SCHEMA>\n",
    "{json.dumps(output_schema, indent=2)}\n",
    "</OUTPUT JSON SCHEMA>\n",
    "\n",
    "I need to be able to parse the json output.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = f\"\"\"\n",
    "Here is the list of chunks, each list element is a dictionary with id and text:\n",
    "{[{\"id\": i, \"text\": data} for i, data in enumerate(data_to_embed)]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate synthetic eval reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up the output and make it a parseable json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_output = response.choices[0].message.content\n",
    "json_output = json_output.replace(\"```json\", \"\")\n",
    "json_output = json_output.replace(\"```\", \"\")\n",
    "json_output = json_output.replace(\"// BEGIN UNANSWERABLE QUESTIONS SECTION (5)\", \"\")\n",
    "json_output = json.loads(json_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the dataset to LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "import os\n",
    "\n",
    "client = Client(api_key=os.environ[\"LANGSMITH_API_KEY\"])\n",
    "\n",
    "dataset_name = \"rag-evaluation-dataset\"\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Dataset for evaluating RAG pipeline\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in json_output:\n",
    "    client.create_example(\n",
    "        dataset_id=dataset.id,\n",
    "        inputs={\"question\": item[\"question\"]},\n",
    "        outputs={\n",
    "            \"ground_truth\": item[\"answer_example\"],\n",
    "            \"context_ids\": item[\"chunk_ids\"],\n",
    "            \"contexts\": [qdrant_client.retrieve(collection_name=\"Amazon-items-collection-02\", ids=[id], with_payload=True)[0].payload[\"text\"] for id in item[\"chunk_ids\"]]\n",
    "        }\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
